{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3952819,"sourceType":"datasetVersion","datasetId":1280375},{"sourceId":11819515,"sourceType":"datasetVersion","datasetId":7423719}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install deepface openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:19.533792Z","iopub.execute_input":"2025-05-16T09:24:19.534100Z","iopub.status.idle":"2025-05-16T09:24:29.000853Z","shell.execute_reply.started":"2025-05-16T09:24:19.534076Z","shell.execute_reply":"2025-05-16T09:24:28.999833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport numpy as np\nfrom deepface import DeepFace\nimport requests\nimport json\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\nfrom openai import OpenAI\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:29.002153Z","iopub.execute_input":"2025-05-16T09:24:29.002411Z","iopub.status.idle":"2025-05-16T09:24:38.069037Z","shell.execute_reply.started":"2025-05-16T09:24:29.002383Z","shell.execute_reply":"2025-05-16T09:24:38.068401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class for Extracting Facial Features using Resnet\nclass FacialFeatureExtractor(nn.Module):\n    def __init__(self, num_features=10):\n        super(FacialFeatureExtractor, self).__init__()\n        # Use a pretrained ResNet as base\n        resnet = models.resnet50(pretrained=True)\n        # Remove the final fully connected layer\n        self.features = nn.Sequential(*list(resnet.children())[:-1])\n        # Add custom layers for specific facial features\n        self.fc1 = nn.Linear(2048, 512)\n        self.fc2 = nn.Linear(512, num_features)\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))  # Sigmoid for feature probabilities\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.070428Z","iopub.execute_input":"2025-05-16T09:24:38.070925Z","iopub.status.idle":"2025-05-16T09:24:38.076157Z","shell.execute_reply.started":"2025-05-16T09:24:38.070901Z","shell.execute_reply":"2025-05-16T09:24:38.075325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Given The Image , DeepFace will Analyze for Facial Features\ndef analyze_facial_features(image_path):\n\n    try:\n        analysis = DeepFace.analyze(img_path=image_path, \n                                   actions=['age', 'gender', 'race', 'emotion'],\n                                   enforce_detection=False,\n                                   detector_backend='retinaface')\n        \n        # Extract key information\n        basic_features = {\n            'age': analysis[0]['age'],\n            'gender': analysis[0]['gender'],\n            'dominant_race': analysis[0]['dominant_race'],\n            'dominant_emotion': analysis[0]['dominant_emotion'],\n            'emotion_scores': analysis[0]['emotion']\n        }\n    \n        return {**basic_features}\n    \n    except Exception as e:\n        print(f\"Error analyzing {image_path}: {str(e)}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.077530Z","iopub.execute_input":"2025-05-16T09:24:38.077815Z","iopub.status.idle":"2025-05-16T09:24:38.095350Z","shell.execute_reply.started":"2025-05-16T09:24:38.077785Z","shell.execute_reply":"2025-05-16T09:24:38.094555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Using Actor's Name and API Prompt, Finding Actor Traits based on the Actor's Roles in Different Movies\ndef get_actor_role_traits(actor_name):\n    \n    prompt = f\"\"\"\n    Analyze actor {actor_name}'s most notable roles and identify 20 common character traits \n    they often portray in movies. Focus on personality traits, physical characteristics they're \n    known for, and types of roles they excel in. Format the response as a JSON list of traits.\n    \"\"\"\n\n    token = '#YOUR API KEY'\n    endpoint = \"https://models.github.ai/inference\"\n    model_name = \"openai/gpt-4o\"\n    \n    try:\n        client = OpenAI(\n            base_url=endpoint,\n            api_key=token,\n        )\n        \n        response = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": prompt,\n                }\n            ],\n            temperature=1.0,\n            top_p=1.0,\n            max_tokens=5000,\n            model=model_name\n        )\n        \n        return response.choices[0].message.content\n        \n    except Exception as e:\n        print(f\"Error getting traits for {actor_name}: {str(e)}\")\n        return \"API_LIMIT_REACHED\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.095992Z","iopub.execute_input":"2025-05-16T09:24:38.096211Z","iopub.status.idle":"2025-05-16T09:24:38.114458Z","shell.execute_reply.started":"2025-05-16T09:24:38.096193Z","shell.execute_reply":"2025-05-16T09:24:38.113886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# From Base Directory, Extract Actor's Name, Actor's Path\ndef extract_actor_names(base_dir):\n    actor_names = []\n    actor_paths = {}\n    \n    for actor_folder in os.listdir(base_dir):\n        folder_path = os.path.join(base_dir, actor_folder)\n        if os.path.isdir(folder_path):\n            actor_names.append(actor_folder)\n            actor_paths[actor_folder] = folder_path\n    \n    return actor_names, actor_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.115140Z","iopub.execute_input":"2025-05-16T09:24:38.115418Z","iopub.status.idle":"2025-05-16T09:24:38.132190Z","shell.execute_reply.started":"2025-05-16T09:24:38.115399Z","shell.execute_reply":"2025-05-16T09:24:38.131369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For each Actor's Image and path, extract its individual Image files and then analyze facial features using DeepFace\ndef process_actor_images(actor_name, actor_path):\n  \n    image_features = []\n    \n    # Get all image files\n    image_files = [f for f in os.listdir(actor_path) \n                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    \n    for img_file in image_files:\n        img_path = os.path.join(actor_path, img_file)\n        features = analyze_facial_features(img_path)\n        if features:\n            image_features.append(features)\n    \n    return image_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.132861Z","iopub.execute_input":"2025-05-16T09:24:38.133038Z","iopub.status.idle":"2025-05-16T09:24:38.147442Z","shell.execute_reply.started":"2025-05-16T09:24:38.133022Z","shell.execute_reply":"2025-05-16T09:24:38.146723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Given Facial Features from DeepFace analysis, Aggregate features will give a cumulitive feature from all the images gathered\n\ndef aggregate_features(facial_features):\n  \n    if not facial_features:\n        return {}\n    \n    # Initialize aggregated features\n    aggregated = {}\n    \n    # Numeric features to average\n    numeric_features = ['age', 'eye_intensity', 'face_seriousness', 'strong_look']\n    \n    # Categorical features to take most common\n    categorical_features = ['gender', 'dominant_race', 'dominant_emotion']\n    \n    # Boolean features (handle separately)\n    boolean_features = ['has_beard']\n    \n    # Process numeric features\n    for feature in numeric_features:\n        if all(feature in item for item in facial_features):\n            aggregated[feature] = sum(item[feature] for item in facial_features) / len(facial_features)\n    \n    # Process categorical features\n    for feature in categorical_features:\n        if all(feature in item for item in facial_features):\n            # Count occurrences\n            counts = {}\n            for item in facial_features:\n                value = item[feature]\n                # Make sure value is hashable (not a dict)\n                if not isinstance(value, dict):\n                    counts[value] = counts.get(value, 0) + 1\n            \n            # Find most common if counts is not empty\n            if counts:\n                most_common = max(counts.items(), key=lambda x: x[1])[0]\n                aggregated[feature] = most_common\n    \n    # Process boolean features\n    for feature in boolean_features:\n        if all(feature in item for item in facial_features):\n            # Count True values\n            true_count = sum(1 for item in facial_features if item[feature])\n            # Set to True if majority are True\n            aggregated[feature] = true_count > len(facial_features) / 2\n    \n    # Special handling for emotion scores\n    if all('emotion_scores' in item for item in facial_features):\n        emotion_scores = {}\n        # Get all possible emotions from the first item\n        if facial_features and len(facial_features) > 0 and 'emotion_scores' in facial_features[0]:\n            emotions = facial_features[0]['emotion_scores'].keys()\n            \n            for emotion in emotions:\n                # Calculate average score for each emotion\n                scores = [item['emotion_scores'].get(emotion, 0) for item in facial_features]\n                emotion_scores[emotion] = sum(scores) / len(scores)\n            \n            aggregated['emotion_scores'] = emotion_scores\n    # Add gender feature explicitly \n    if all('gender' in item for item in facial_features):\n        gender_counts = {}\n        for item in facial_features:\n            gender = item['gender']\n            # Check if gender is a dictionary\n            if isinstance(gender, dict):\n                # Either extract a specific value from the dictionary\n                # or convert it to a string representation\n                gender = str(gender)  # or some other appropriate conversion\n            gender_counts[gender] = gender_counts.get(gender, 0) + 1\n    \n    return aggregated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.149019Z","iopub.execute_input":"2025-05-16T09:24:38.149249Z","iopub.status.idle":"2025-05-16T09:24:38.170107Z","shell.execute_reply.started":"2025-05-16T09:24:38.149231Z","shell.execute_reply":"2025-05-16T09:24:38.169319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save Current Progress\ndef save_progress(processed_actors):\n\n    # Save processed actors list\n    with open(\"processed_actors.json\", \"w\") as f:\n        json.dump(processed_actors, f, indent=2)\n    \n    # Save checkpoint with timestamp\n    checkpoint = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"processed_count\": len(processed_actors)\n    }\n    \n    with open(\"actor_processing_checkpoint.json\", \"w\") as f:\n        json.dump(checkpoint, f, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:24:38.171081Z","iopub.execute_input":"2025-05-16T09:24:38.171368Z","iopub.status.idle":"2025-05-16T09:24:38.188041Z","shell.execute_reply.started":"2025-05-16T09:24:38.171342Z","shell.execute_reply":"2025-05-16T09:24:38.187214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Processing Actors with given base_dir\ndef process_actors_batch(base_dir):\n    \n    actor_names, actor_paths = extract_actor_names(base_dir)\n    \n    processed_actors = {}\n    if os.path.exists(\"/kaggle/input/actorsfinal/cleaned_data.json\"):\n        with open(\"/kaggle/input/actorsfinal/cleaned_data.json\", \"r\") as f:\n            processed_actors = json.load(f)\n    \n    # Load the complete list of actors\n    all_actors = []\n    with open(\"/kaggle/input/indian-actor-images-dataset/List of Actors.txt\", \"r\") as f:\n        all_actors = [line.strip() for line in f if line.strip()]\n\n    print(processed_actors.keys())\n    processed_actor_names = set(processed_actors.keys())\n    remaining_actors = [actor for actor in all_actors if actor not in processed_actor_names]\n    \n    print(f\"Total actors in list: {len(all_actors)}\")\n    print(f\"Already processed: {len(processed_actor_names)}\")\n    print(f\"Remaining to process: {len(remaining_actors)}\")\n    \n    for actor in remaining_actors:\n        print(f\"Processing actor: {actor}\")\n        \n        # Get actor's common role traits\n        role_traits = get_actor_role_traits(actor)\n        \n        # Check if API limit was reached\n        if role_traits == \"API_LIMIT_REACHED\":\n            print(\"Stopping processing due to API limit.\")\n            break\n        \n        # Process all images and extract facial features\n        facial_features = process_actor_images(actor, actor_paths[actor])\n        \n        # Create comprehensive profile\n        processed_actors[actor] = {\n            'role_traits': role_traits,\n            'aggregated_features': aggregate_features(facial_features)\n        }\n        \n        # Save progress after each actor\n        save_progress(processed_actors)\n\n        print(f\"Completed processing {actor}\")\n        \n        # Add a small delay to avoid hitting rate limits too quickly\n        time.sleep(1)\n    \n    return processed_actors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:28:15.515424Z","iopub.execute_input":"2025-05-16T09:28:15.515735Z","iopub.status.idle":"2025-05-16T09:28:15.522294Z","shell.execute_reply.started":"2025-05-16T09:28:15.515709Z","shell.execute_reply":"2025-05-16T09:28:15.521397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    \n    base_dir = \"/kaggle/input/indian-actor-images-dataset/Bollywood Actor Images/Bollywood Actor Images\"\n\n    # Process actors until limit reached\n    processed_actors = process_actors_batch(\n        base_dir, \n    )\n\n    # Output current database status\n    print(f\"\\nCurrent database contains {len(processed_actors)} actors\")\n    print(f\"Remaining actors will be processed in the next run\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:28:15.926076Z","iopub.execute_input":"2025-05-16T09:28:15.926374Z","iopub.status.idle":"2025-05-16T09:28:15.930450Z","shell.execute_reply.started":"2025-05-16T09:28:15.926351Z","shell.execute_reply":"2025-05-16T09:28:15.929544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T09:28:17.860734Z","iopub.execute_input":"2025-05-16T09:28:17.861043Z","iopub.status.idle":"2025-05-16T09:28:17.874742Z","shell.execute_reply.started":"2025-05-16T09:28:17.861019Z","shell.execute_reply":"2025-05-16T09:28:17.873895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Role traits are not in clean format and are in String format, therefore converting them to JSON format\n\nimport json\nimport re\n\n# Load the raw JSON file\nwith open(\"/kaggle/input/actorsfinal/processed_actors.json\", \"r\") as file:\n    data = json.load(file)\n\n# Iterate through each key (actor)\nfor name, details in data.items():\n    raw_traits = details.get(\"role_traits\", None)\n\n    # Proceed only if role_traits is a string and contains list structure\n    if isinstance(raw_traits, str):\n        # Use regex to extract the JSON list part (between first '[' and last ']')\n        match = re.search(r'\\[\\s*{.*?}\\s*\\]', raw_traits, re.DOTALL)\n        if match:\n            json_like_str = match.group(0)\n            try:\n                parsed_traits = json.loads(json_like_str)\n                data[name][\"role_traits\"] = parsed_traits\n            except json.JSONDecodeError as e:\n                print(f\"[JSONDecodeError] Could not parse 'role_traits' for {name}: {e}\")\n        else:\n            print(f\"[Warning] No JSON array found in 'role_traits' for {name}\")\n    else:\n        print(f\"[Info] Skipped {name} (already parsed or not a string)\")\n\n# Save the cleaned data\nwith open(\"cleaned_data.json\", \"w\") as out_file:\n    json.dump(data, out_file, indent=4)\n\nprint(\"Cleaning complete. Output written to 'cleaned_data.json'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T07:31:16.418757Z","iopub.execute_input":"2025-05-15T07:31:16.419103Z","iopub.status.idle":"2025-05-15T07:31:16.464583Z","shell.execute_reply.started":"2025-05-15T07:31:16.419076Z","shell.execute_reply":"2025-05-15T07:31:16.463784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T09:46:46.621744Z","iopub.execute_input":"2025-05-15T09:46:46.622156Z","iopub.status.idle":"2025-05-15T09:46:50.981139Z","shell.execute_reply.started":"2025-05-15T09:46:46.622122Z","shell.execute_reply":"2025-05-15T09:46:50.979975Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Here we are generating a summary parameter in json file having a summary of all the traits**","metadata":{}},{"cell_type":"code","source":"import json\nfrom transformers import pipeline\n\n# Load the summarizer model\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n\n# Load the input data\nwith open(\"/kaggle/input/actorsfinal/cleaned_data.json\", \"r\") as f:\n    data = json.load(f)\n\n# Loop through each actor\nfor name, details in data.items():\n    summary_input_parts = []\n\n    # Role Traits\n    role_traits = details.get(\"role_traits\", [])\n    if isinstance(role_traits, list):\n        trait_text = \" \".join([f\"{trait['trait']}: {trait['description']}\" for trait in role_traits])\n        summary_input_parts.append(trait_text)\n\n    # Aggregated Features\n    agg = details.get(\"aggregated_features\", {})\n    if agg:\n        age = agg.get(\"age\", None)\n        dom_race = agg.get(\"dominant_race\", None)\n        dom_emotion = agg.get(\"dominant_emotion\", None)\n\n        # Basic summary of features\n        feature_text = f\"Age: {age}. Dominant Race: {dom_race}. Dominant Emotion: {dom_emotion}.\"\n        summary_input_parts.append(feature_text)\n\n        # Optional: Add full emotion scores\n        scores = agg.get(\"emotion_scores\", {})\n        if scores:\n            score_text = \"Emotion Scores - \" + \", \".join([f\"{k}: {round(v, 1)}%\" for k, v in scores.items()])\n            summary_input_parts.append(score_text)\n\n    # Combine all into one summarizable block\n    final_text = \" \".join(summary_input_parts)\n    final_text = final_text[:3000]  # limit input size if needed\n    print(f\"For {name}:  {final_text}\")\n\n    try:\n        summary = summarizer(final_text, max_length=300, min_length=150, do_sample=False)[0][\"summary_text\"]\n        data[name][\"summary\"] = summary\n        print(f\"[✓] Summary added for {name}\")\n        print(summary)\n    except Exception as e:\n        print(f\"[✗] Failed to summarize for {name}: {e}\")\n\n# Save to file\nwith open(\"summarized_full_data.json\", \"w\") as f:\n    json.dump(data, f, indent=4)\n\nprint(\" Summarization complete. Output saved to 'summarized_full_data.json'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T09:49:22.233242Z","iopub.execute_input":"2025-05-15T09:49:22.233945Z","iopub.status.idle":"2025-05-15T10:37:03.485946Z","shell.execute_reply.started":"2025-05-15T09:49:22.233917Z","shell.execute_reply":"2025-05-15T10:37:03.485061Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install sentence-transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:13:05.626408Z","iopub.execute_input":"2025-05-15T11:13:05.626760Z","iopub.status.idle":"2025-05-15T11:13:09.294040Z","shell.execute_reply.started":"2025-05-15T11:13:05.626737Z","shell.execute_reply":"2025-05-15T11:13:09.293063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In this we are embedding the summary and user query and finding the best cosine similarity.\n\nimport json\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# Load summaries\nwith open(\"/kaggle/working/summarized_full_data.json\", \"r\") as f:\n    actor_data = json.load(f)\n\n# Load sentence embedding model\nmodel = SentenceTransformer(\"all-mpnet-base-v2\")\n\n# Extract summaries and corresponding actor names\nactor_summaries = {actor: details['summary'] for actor, details in data.items()}\n\n# Function to recommend actors\ndef recommend_actors(user_description, top_k=5):\n    # Get embedding for user query\n    query_embedding = model.encode(user_description, convert_to_tensor=True)\n\n    # Compute similarity between user query and each actor's summary\n    similarities = []\n    for actor, summary in actor_summaries.items():\n        summary_embedding = model.encode(summary, convert_to_tensor=True)\n        score = util.cos_sim(query_embedding, summary_embedding).item()\n        similarities.append((actor, score))\n\n    # Sort by similarity score and return top matches\n    top_matches = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n    return top_matches\n\nquery = \"Army look, strong and bold personality and voice, Have aggressive eyes\"\n\ntop_actors = recommend_actors(query)\nprint(\"Recommended Actors:\")\nfor actor, score in top_actors:\n    print(f\"{actor}: similarity = {score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:18:00.424441Z","iopub.execute_input":"2025-05-15T11:18:00.425143Z","iopub.status.idle":"2025-05-15T11:18:05.394103Z","shell.execute_reply.started":"2025-05-15T11:18:00.425112Z","shell.execute_reply":"2025-05-15T11:18:05.393462Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2nd WAY OF RECOMMENDATION i.e. just matching from JSON format instead of summaries\n\ndef recommend_actors(actor_profiles, role_requirements, top_n=3):\n\n    scores = {}\n    \n    # Parse role requirements\n    req_traits = role_requirements.get('traits', [])\n    req_facial = role_requirements.get('facial_features', {})\n    \n    for actor_name, profile in actor_profiles.items():\n        score = 0\n        \n        # Score based on role traits\n        actor_traits = profile['role_traits']\n        for trait in req_traits:\n            if any(trait.lower() in actor_trait['trait'].lower() for actor_trait in actor_traits):\n                score += 1\n        \n        # Score based on facial features\n        agg_features = profile['aggregated_features']\n        \n        # Age proximity (if specified)\n        if 'age' in req_facial and 'age' in agg_features:\n            age_diff = abs(req_facial['age'] - agg_features['age'])\n            # Convert age difference to a score (closer is better)\n            age_score = max(0, 1 - (age_diff / 50))  # Normalize by 50 years\n            score += age_score * 2  # Weight age more heavily\n        \n        # Gender match (if specified)\n        if 'gender' in req_facial and 'gender' in agg_features:\n            if req_facial['gender'].lower() == agg_features['gender'].lower():\n                score += 2\n        \n        # Emotion match (if specified)\n        if 'dominant_emotion' in req_facial and 'dominant_emotion' in agg_features:\n            if req_facial['dominant_emotion'].lower() == agg_features['dominant_emotion'].lower():\n                score += 1\n        \n        # Other facial features\n        for feature in ['has_beard', 'eye_intensity', 'face_seriousness', 'strong_look']:\n            if feature in req_facial and feature in agg_features:\n                if isinstance(agg_features[feature], bool):\n                    # Boolean feature\n                    if req_facial[feature] == agg_features[feature]:\n                        score += 1\n                else:\n                    # Numeric feature - calculate proximity (closer is better)\n                    diff = abs(req_facial[feature] - agg_features[feature])\n                    feature_score = max(0, 1 - diff)  # Normalize to 0-1\n                    score += feature_score\n        \n        scores[actor_name] = score\n    \n    # Sort actors by score and return top N\n    top_actors = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n    \n    return top_actors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:25:28.196785Z","iopub.execute_input":"2025-05-15T11:25:28.197171Z","iopub.status.idle":"2025-05-15T11:25:28.205607Z","shell.execute_reply.started":"2025-05-15T11:25:28.197134Z","shell.execute_reply":"2025-05-15T11:25:28.204376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \n\nactor_profiles = {}\n    \n# Load actor profiles if exists\nif os.path.exists(\"/kaggle/input/actorsfinal/cleaned_data.json\"):\n    with open(\"/kaggle/input/actorsfinal/cleaned_data.json\", \"r\") as f:\n        actor_profiles = json.load(f)\n\n# Example role requirement for testing recommendations\nif len(actor_profiles) > 0:\n    example_role = {\n        'traits': ['intense', 'authoritative', 'Strong and bold voice', 'Rajputana Look'],\n        'facial_features': {\n            'age': 40,\n            'gender': 'Male',\n            'has_beard': False,\n            'eye_intensity': 0.8,\n            'face_seriousness': 0.7,\n            'strong_look': 0.9,\n            'dominant_emotion': 'angry'\n        }\n    }\n    \n    # Get recommendations\n    print(\"\\nFinding best actors for the role...\")\n    recommendations = recommend_actors(actor_profiles, example_role, top_n=3)\n    \n    # Display recommendations\n    print(\"\\nTop Recommended Actors:\")\n    for i, (actor, score) in enumerate(recommendations, 1):\n        print(f\"{i}. {actor} (Score: {score:.2f})\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:28:26.356405Z","iopub.execute_input":"2025-05-15T11:28:26.356742Z","iopub.status.idle":"2025-05-15T11:28:26.371657Z","shell.execute_reply.started":"2025-05-15T11:28:26.356713Z","shell.execute_reply":"2025-05-15T11:28:26.370626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"** Since The above 2 recommendations are giving different result , therefore approach is to get Hybrid of these 2 recommendation functions and combined score, then result of Top n actors**","metadata":{}},{"cell_type":"code","source":"# Load structured profiles\nwith open(\"/kaggle/input/actorsfinal/cleaned_data.json\", \"r\") as f:\n    actor_profiles = json.load(f)\n\n# Load summarized text data\nwith open(\"/kaggle/working/summarized_full_data.json\", \"r\") as f:\n    actor_data = json.load(f)\nactor_summaries = {actor: details['summary'] for actor, details in actor_data.items()}\n\n# Load sentence transformer model\nmodel = SentenceTransformer(\"all-mpnet-base-v2\")\n\n\n# ------------------------------\n# Structured Matching Function\n# ------------------------------\ndef compute_trait_score(actor_traits, query_traits):\n    match_count = sum(1 for qt in query_traits if any(qt.lower() in at['trait'].lower() for at in actor_traits))\n    return match_count / len(query_traits) if query_traits else 0\n\n\ndef compute_feature_score(actor_features, query_features):\n    score = 0\n    max_score = 0\n\n    # Age similarity\n    if 'age' in actor_features and 'age' in query_features:\n        age_diff = abs(actor_features['age'] - query_features['age'])\n        age_score = max(0, 1 - age_diff / 30)  # normalize\n        score += age_score\n        max_score += 1\n\n    # Dominant emotion match\n    if 'dominant_emotion' in actor_features and 'dominant_emotion' in query_features:\n        score += int(actor_features['dominant_emotion'] == query_features['dominant_emotion'])\n        max_score += 1\n\n    return score / max_score if max_score else 0\n\n\ndef get_structured_score(actor_name, role):\n    traits_score = compute_trait_score(actor_profiles[actor_name]['role_traits'], role['traits'])\n    features_score = compute_feature_score(actor_profiles[actor_name]['aggregated_features'], role['facial_features'])\n    return (traits_score + features_score) / 2\n\n\n# ------------------------------\n# Embedding Similarity Function\n# ------------------------------\ndef get_summary_similarity(actor_name, role_text):\n    actor_summary = actor_summaries.get(actor_name, \"\")\n    if not actor_summary:\n        return 0\n    query_embedding = model.encode(role_text, convert_to_tensor=True)\n    summary_embedding = model.encode(actor_summary, convert_to_tensor=True)\n    return util.cos_sim(query_embedding, summary_embedding).item()\n\n\n# ------------------------------\n# Final Recommender\n# ------------------------------\ndef hybrid_recommend_actors(role, role_text_description, top_n=5, w_structured=0.6, w_text=0.4):\n    scores = []\n\n    for actor_name in actor_profiles.keys():\n        structured_score = get_structured_score(actor_name, role)\n        text_score = get_summary_similarity(actor_name, role_text_description)\n        final_score = w_structured * structured_score + w_text * text_score #Here taking 60% weightage to structured data ad 40% weightage to Summary data\n        scores.append((actor_name, final_score))\n\n    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n    return sorted_scores[:top_n]\n\n\nexample_role = {\n    'traits': ['intense', 'authoritative', 'Strong and bold voice', 'Rajputana Look'],\n    'facial_features': {\n        'age': 40,\n        'gender': 'Male',\n        'has_beard': False,\n        'eye_intensity': 0.8,\n        'face_seriousness': 0.7,\n        'strong_look': 0.9,\n        'dominant_emotion': 'angry'\n    }\n}\nrole_text = \"Army look, strong and bold personality and voice, aggressive eyes, Rajputana heritage\"\n\nprint(\"\\n Top Hybrid Recommended Actors:\")\ntop_actors = hybrid_recommend_actors(example_role, role_text)\nfor i, (actor, score) in enumerate(top_actors, 1):\n    print(f\"{i}. {actor} — Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:54:42.807781Z","iopub.execute_input":"2025-05-15T11:54:42.808217Z","iopub.status.idle":"2025-05-15T11:54:51.151510Z","shell.execute_reply.started":"2025-05-15T11:54:42.808181Z","shell.execute_reply":"2025-05-15T11:54:51.150832Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}